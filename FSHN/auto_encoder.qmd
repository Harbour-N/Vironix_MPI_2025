---
title: GAN using autoencoders
description: balalalbadldb
authors:
  - name: Nicholas Harbour
format: 
  html:
    embed-resources: true
    code-fold: true
    number-sections: true
    toc: true
    toc-depth: 3
    date: now
    date-modified: last-modified
    date-format: "MMMM DD, YYYY, HH:mm:ss"
jupyter: python3
---



# Import required libraries



```{python}

import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
import numpy as np

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')



```


# Download the Fashion MNIST dataset

```{python}

# Hyperparameters
batch_size = 128
learning_rate = 1e-3
num_epochs = 10
latent_dim = 32

# Data loading and preprocessing
transform = transforms.ToTensor()

train_dataset = datasets.FashionMNIST(root='./MNIST_fashion', train=True, download=True, transform=transform)
test_dataset = datasets.FashionMNIST(root='./MNIST_fashion', train=False, download=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)


```


# Basic EDA

```{python}

print(f'Train dataset size: {len(train_dataset)}')
print(f'Test dataset size: {len(test_dataset)}')

print(f'Number of classes: {len(train_dataset.classes)}')
print(f'Classes: {train_dataset.classes}')

print(f'Image shape: {train_dataset[0][0].shape}')  # Shape of the first image


```


# Define the Autoencoder model

```{python}

# Define the Autoencoder
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        # Encoder
        self.encoder = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28*28, 128),
            nn.ReLU(),
            nn.Linear(128, latent_dim)
        )
        # Decoder
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 28*28),
            nn.Sigmoid(),  # Ensure outputs are between 0 and 1
            nn.Unflatten(1, (1, 28, 28))
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# Instantiate model, loss, and optimizer
model = Autoencoder().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# Training loop
for epoch in range(num_epochs):
    total_loss = 0
    for images, _ in train_loader:
        images = images.to(device)
        
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, images)

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')




```


# Visualise the embedding space of the autoencoder


```{python}


# Get the embedding of a single image
def get_embedding(model, image_tensor):
    model.eval()
    with torch.no_grad():
        image_tensor = image_tensor.unsqueeze(0).to(device)  # Add batch dimension: (1, 1, 28, 28)
        embedding = model.encoder(image_tensor)
    return embedding.squeeze().cpu()  # Remove batch dimension and move to CPU

# Take one image from test set
sample_image, label = test_dataset[0]

# Get the embedding
embedding = get_embedding(model, sample_image)

print(f'Label: {label}')
print(f'Embedding shape: {embedding.shape}')
print(f'Embedding vector:\n{embedding}')


```


```{python}

x = np.zeros((len(test_dataset), latent_dim))
y = np.zeros(len(test_dataset))

for i, (image, label) in enumerate(test_dataset):
    embedding = get_embedding(model, image)
    x[i] = embedding.numpy()
    y[i] = label  # Store the label



```


perfom PCA to plot the embedding space

```{python}


pca = PCA(n_components=2)
x_pca = pca.fit_transform(x)

```


```{python}


scatter = plt.scatter(x_pca[:, 0], x_pca[:, 1], c=y, cmap='tab10', s=10, alpha=0.7)
plt.title('PCA of Autoencoder Embeddings')
plt.xlabel('PCA Component 1')
plt.ylabel('PCA Component 2')
plt.colorbar(scatter, ticks=range(10), label='Label')
plt.clim(-0.5, 9.5)
plt.grid(True)
plt.show()

```


```{python}

# Visualize reconstructions
def show_reconstructions(model, data_loader, num_images=10):
    model.eval()
    with torch.no_grad():
        images, _ = next(iter(data_loader))
        images = images[:num_images].to(device)
        outputs = model(images)

    images = images.cpu().numpy()
    outputs = outputs.cpu().numpy()

    fig, axes = plt.subplots(2, num_images, figsize=(num_images, 2))
    for i in range(num_images):
        axes[0, i].imshow(images[i].squeeze(), cmap='gray')
        axes[0, i].axis('off')
        axes[1, i].imshow(outputs[i].squeeze(), cmap='gray')
        axes[1, i].axis('off')
    axes[0, 0].set_ylabel('Original', fontsize=12)
    axes[1, 0].set_ylabel('Reconstructed', fontsize=12)
    plt.tight_layout()
    plt.show()

# Show reconstructions
show_reconstructions(model, test_loader)


```



# Train a discriminator to classify the embeddings


```{python}

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(256, 1),
            nn.Sigmoid()  # Outputs a probability that the image is real
        )

    def forward(self, x):
        return self.model(x)



```



```{python}

# Instantiate the Discriminator and define loss and optimizer
discriminator = Discriminator().to(device)
d_criterion = nn.BCELoss()
d_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)

# Number of epochs for discriminator training
num_d_epochs = 5

# Training loop for discriminator
for epoch in range(num_d_epochs):
    total_loss = 0
    discriminator.train()

    for real_images, _ in train_loader:
        real_images = real_images.to(device)
        
        # -----------------------------
        # Train on real images (label = 1)
        # -----------------------------
        real_labels = torch.ones(real_images.size(0), 1).to(device)
        real_preds = discriminator(real_images)
        real_loss = d_criterion(real_preds, real_labels)

        # -----------------------------
        # Train on fake images (reconstructed, label = 0)
        # -----------------------------
        with torch.no_grad():  # Do not backprop into autoencoder
            fake_images = model(real_images)
        fake_labels = torch.zeros(fake_images.size(0), 1).to(device)
        fake_preds = discriminator(fake_images)
        fake_loss = d_criterion(fake_preds, fake_labels)

        # -----------------------------
        # Backpropagation
        # -----------------------------
        loss = real_loss + fake_loss
        d_optimizer.zero_grad()
        loss.backward()
        d_optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f'[Epoch {epoch+1}/{num_d_epochs}] Discriminator Loss: {avg_loss:.4f}')



```


```{python}


def evaluate_discriminator(discriminator, model, data_loader):
    discriminator.eval()
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, _ in data_loader:
            images = images.to(device)
            real_preds = discriminator(images)
            fake_images = model(images)
            fake_preds = discriminator(fake_images)

            real_preds_label = (real_preds > 0.5).float()
            fake_preds_label = (fake_preds > 0.5).float()

            correct += real_preds_label.sum().item()
            correct += (1 - fake_preds_label).sum().item()
            total += 2 * images.size(0)

    accuracy = correct / total
    print(f'Discriminator Accuracy: {accuracy:.4f}')


```


```{python}


# Evaluate the discriminator
evaluate_discriminator(discriminator, model, test_loader)

```



